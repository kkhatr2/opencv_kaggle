{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c5326-c045-4ff3-b7fd-d9eee1a44665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from PIL import Image as im\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics import Accuracy, MeanMetric\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab0e0d0-424c-4be9-9bfe-ee330038ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_root, img_size, batch_size=32, train_split=0.8, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.root = data_root\n",
    "        self.metadata = self.get_metadata()\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.num_workers = num_workers\n",
    "        self.train_mean = [0.0, 0., 0.0]\n",
    "        self.train_std = [1.0, 1.0, 1.0]\n",
    "        self.common_transforms = transforms.Compose([\n",
    "            transforms.Resize((img_size + 20, img_size + 20), \n",
    "                              transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            \n",
    "        ])\n",
    "        \n",
    "    \n",
    "    def prepare_data_per_node(self):\n",
    "        # There is nothing to prepare.\n",
    "        # The data should have already been downloaded and\n",
    "        # extracted in the data_root that is passed to initiaize this class\n",
    "        print(os.path.abspath(self.root))\n",
    "        \n",
    "    \n",
    "    def setup(self, stage='fit'):\n",
    "        data_dict = self.get_img_path_labels(stage)\n",
    "        imgs_ct = len(data_dict['image_path'])\n",
    "        imgs_tensor = torch.empty([imgs_ct, 3, self.img_size, self.img_size])\n",
    "        labels_tensor = torch.empty(imgs_ct, dtype=int)\n",
    "       \n",
    "        for i in range(imgs_ct):\n",
    "            img = im.open(data_dict['image_path'][i]).convert(\"RGB\")\n",
    "            img = self.common_transforms(img)\n",
    "            imgs_tensor[i] = img\n",
    "            labels_tensor[i] = data_dict['label'][i]\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.mean, self.std = self.compute_mean_std(imgs_tensor)\n",
    "            imgs_tensor = transforms.functional.normalize(imgs_tensor, self.mean, self.std)\n",
    "            final_dataset = tuple(map(lambda x, y: (x, y,), imgs_tensor, labels_tensor))\n",
    "            train_split = torch.ceil(torch.tensor(imgs_ct * self.train_split)).to(int).item()\n",
    "            self.train_set, self.val_set = random_split(final_dataset, [train_split, imgs_ct-train_split])\n",
    "        else:\n",
    "            imgs_tensor = transforms.functional.normalize(imgs_tensor, self.mean, self.std)\n",
    "            self.test_set = tuple(map(lambda x, y: (x, y), imgs_tensor, labels_tensor))\n",
    "            \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    #############################\n",
    "    ## Miscellaneous functions ##\n",
    "    #############################\n",
    "    def compute_mean_std(self, image_tensor):\n",
    "        axes = (0,2,3)\n",
    "        return image_tensor.mean(axis=axes), image_tensor.std(axis=axes)\n",
    "        \n",
    "    def get_img_path_labels(self, stage='fit'):\n",
    "        data_dict = {'image_path':[], 'label':[]}\n",
    "        if stage == 'fit':\n",
    "            dir_ = os.path.join(self.root, 'training', 'training')\n",
    "        else:\n",
    "            dir_ = os.path.join(self.root, 'validation', 'validation')\n",
    "            \n",
    "        for cl in self.metadata['Label']:\n",
    "            class_path = os.path.join(dir_, cl)\n",
    "            for img in os.listdir(class_path):\n",
    "                if img.endswith(\".jpg\") or img.endswith(\".png\"):\n",
    "                    fname = os.path.join(class_path, img)\n",
    "                    data_dict['image_path'].append(fname)\n",
    "                    data_dict['label'].append(int(cl[1]))\n",
    "        \n",
    "        return data_dict\n",
    "\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        metadata = dict()\n",
    "        with open(os.path.join(self.root, 'monkey_labels.txt'), mode ='r') as file:\n",
    "            csvFile = csv.reader(file)            \n",
    "            headers = [r.strip() for r in  next(csvFile)]\n",
    "            \n",
    "            for h in headers:\n",
    "                metadata[h] = []\n",
    "                \n",
    "            for lines in csvFile:\n",
    "                for i in range(len(lines)):\n",
    "                    metadata[headers[i]].append(lines[i].strip())\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d50e7d-5a0b-41ff-8bf4-017450755d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonkeyType(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=3e-4, num_classes=10, input_shape=10):\n",
    "        super().__init__()        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # to log the model architecture on tensorboard\n",
    "        self.example_input_array = torch.rand((1, 3, self.hparams.input_shape, self.hparams.input_shape))\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((5,5))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 5 * 5, self.hparams.num_classes)\n",
    "        )\n",
    "        \n",
    "        # Model Metrics for logging\n",
    "        acc_obj = Accuracy(num_classes=self.hparams.num_classes)\n",
    "        # use .clone() so that each metric can maintain its own state\n",
    "        self.train_acc = acc_obj.clone()\n",
    "        self.val_acc = acc_obj.clone()\n",
    "        \n",
    "        loss_obj = MeanMetric()\n",
    "        self.train_loss = loss_obj.clone()\n",
    "        self.val_loss = loss_obj.clone()\n",
    "        # End Model Metrics for logging\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        super().on_train_epoch_start()\n",
    "\n",
    "        # Reset state variables for train metrics to \n",
    "        # their default values before start of each epoch\n",
    "        self.train_acc.reset()\n",
    "        self.train_loss.reset()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        pred = self(imgs)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        probs = F.softmax(pred, dim=1)\n",
    "        pred_classes = probs.argmax(dim=1)\n",
    "        \n",
    "        # accumulate training accuracy for each batch\n",
    "        acc = self.train_acc(pred_classes, labels)\n",
    "        # accumulate training loss for each batch\n",
    "        self.train_loss(loss)\n",
    "        \n",
    "        self.log(\"train/batch_loss\", loss, prog_bar=False)\n",
    "        self.log(\"train/batch_acc\", acc, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        avg_train_acc = self.train_acc.compute()\n",
    "        avg_train_loss = self.train_loss.compute()\n",
    "        self.log(\"train/loss\", avg_train_loss, prog_bar=True)\n",
    "        self.log(\"train/acc\", avg_train_acc, prog_bar=True)\n",
    "        # Set X-axis as epoch number for epoch-level metrics\n",
    "        self.log(\"step\", float(self.current_epoch))\n",
    "        \n",
    "    def on_validation_epoch_start(self):\n",
    "        super().on_validation_epoch_start()\n",
    "\n",
    "        # Reset state variables for validation metrics to \n",
    "        # their default values before start of each epoch\n",
    "\n",
    "        self.val_acc.reset()\n",
    "        self.val_loss.reset()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        output = self(imgs)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        pred_classes = prob.argmax(dim=1)\n",
    "        \n",
    "        # accumulate validation accuracy for each batch\n",
    "        self.val_acc(pred_classes, labels)\n",
    "        self.val_loss(loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        avg_val_loss = self.val_loss.compute()\n",
    "        avg_val_acc = self.val_acc.compute()\n",
    "        self.log('val/loss', avg_val_loss, prog_bar=True)\n",
    "        self.log('val/acc', avg_val_acc, prog_bar=True)\n",
    "        self.log(\"step\", float(self.current_epoch))\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        pred = self(imgs)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        prob = F.softmax(pred, dim=1)\n",
    "        pred_classes = prob.argmax(dim=1)\n",
    "        test_acc = torch.where(pred_classes == labels, 1, 0).to(torch.float32).mean()\n",
    "        self.log('test/loss', loss)\n",
    "        self.log('test/acc', test_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71486e9-3c3f-4f4b-9298-e5c40a9fde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 10\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(10, workers=True)\n",
    "image_size = 32\n",
    "m = MonkeyType(input_shape=image_size)\n",
    "d = PLDataModule('./../monkeys/', img_size=image_size, batch_size=32, train_split=0.80, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9aab32d-aef1-48cc-88ef-d51cfb98f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\", log_graph=True, default_hp_metric=False)\n",
    "trainer = pl.Trainer(accelerator='cpu',\n",
    "                     devices=1,\n",
    "                     fast_dev_run=False,\n",
    "                     enable_progress_bar=True,\n",
    "                     enable_checkpointing=False,\n",
    "                     enable_model_summary=True,\n",
    "                     deterministic=True,\n",
    "                     logger=logger,\n",
    "                     log_every_n_steps=20,\n",
    "                     max_epochs=20,\n",
    "                     check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256c3500-3bcb-4751-a231-7c0c372c98e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: tb_logs/my_model\n",
      "\n",
      "  | Name       | Type              | Params | In sizes       | Out sizes   \n",
      "---------------------------------------------------------------------------------\n",
      "0 | avg_pool   | AdaptiveAvgPool2d | 0      | [1, 3, 32, 32] | [1, 3, 5, 5]\n",
      "1 | fc         | Sequential        | 760    | [1, 3, 5, 5]   | [1, 10]     \n",
      "2 | train_acc  | Accuracy          | 0      | ?              | ?           \n",
      "3 | val_acc    | Accuracy          | 0      | ?              | ?           \n",
      "4 | train_loss | MeanMetric        | 0      | ?              | ?           \n",
      "5 | val_loss   | MeanMetric        | 0      | ?              | ?           \n",
      "---------------------------------------------------------------------------------\n",
      "760       Trainable params\n",
      "0         Non-trainable params\n",
      "760       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e085381e9587437790df7047605774db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f53570-ffa2-4835-a650-121cef60149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a633cc6b84e3a97d24446adf2abf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.3970588147640228\n",
      "        test/loss            1.839987874031067\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 1.839987874031067, 'test/acc': 0.3970588147640228}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e311f043-937c-422f-90c6-e5d98a44fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patas_monkey\n",
      "erythrocebus_patas\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = d.train_dataloader()\n",
    "dsi = iter(ds)\n",
    "ds1 = next(dsi)\n",
    "a, b = ds1\n",
    "idx = torch.randint(0, 20, (1,)).item()\n",
    "a = ((a[idx].permute(1,2,0) * d.std + d.mean) * 255).clamp(0, 255).to(torch.uint8).numpy()\n",
    "print(d.metadata['Common Name'][int(b[idx])])\n",
    "print(d.metadata['Latin Name'][int(b[idx])])\n",
    "im.fromarray(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
